{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Machine Learning and Business Use Case\n",
    "\n",
    "Now your manager has a basic understanding of why customers returned orders. Next, he wants you to use machine learning to predict which orders are most likely to be returned. In this part, you will generate several features based on our previous findings and your manager's requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Feature Engineering\n",
    "#### Step 1: Create the dependent variable\n",
    "- First of all, we need to generate a categorical variable which indicates whether an order has been returned or not.\n",
    "- ***Hint:*** the returned orders’ IDs are contained in the dataset “returns”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders1 = pd.read_csv('../data/Orders.csv')\n",
    "returns1 = pd.read_csv('../data/Returns.csv')\n",
    "returns1.columns = ['Returns', 'Order.ID', 'Region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_orders = pd.merge(orders1, returns1, left_on='Order.ID', right_on='Order.ID', how='outer')\n",
    "new_orders['Returns']=new_orders['Returns'].fillna('No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 2:\n",
    "- Your manager believes that **how long it took the order to ship** would affect whether the customer would return it or not. \n",
    "- He wants you to generate a feature which can measure how long it takes the company to process each order.\n",
    "- ***Hint:*** Process.Time = Ship.Date - Order.Date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_orders['Ship.Date']= pd.to_datetime(new_orders['Ship.Date'])\n",
    "new_orders['Order.Date']= pd.to_datetime(new_orders['Order.Date'])\n",
    "new_orders['Process.Time'] = new_orders['Ship.Date'].sub(new_orders['Order.Date'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3:\n",
    "\n",
    "- If a product has been returned before, it may be returned again. \n",
    "- Let us generate a feature that indicates how many times the product has been returned before.\n",
    "- If it never got returned, we just impute using 0.\n",
    "- ***Hint:*** Group by different Product.ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change settings to allow all the columns to be displayed\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp table -> holds number counts of products returned\n",
    "temp = pd.DataFrame(new_orders[new_orders['Returns']=='Yes'].groupby('Product.ID').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with temp table\n",
    "new_orders = new_orders.merge(temp, on=\"Product.ID\", how=\"outer\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with zero\n",
    "new_orders[0].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change type of new column to Integer\n",
    "new_orders[0] = new_orders[0].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column \"0\" to \"Times.Returned\"\n",
    "new_orders.rename(columns={0: \"Times.Returned\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Problem 5: Fitting Models\n",
    "\n",
    "- You can use any binary classification method you have learned so far.\n",
    "- Use 80/20 training and test splits to build your model. \n",
    "- Double check the column types before you fit the model.\n",
    "- Only include useful features. i.e all the `ID`s should be excluded from your training set.\n",
    "- Note that there are only less than 5% of the orders have been returned, so you should consider using the [createDataPartition](https://www.rdocumentation.org/packages/caret/versions/6.0-80/topics/createDataPartition) function from `caret` package and [StratifiedKfold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn-model-selection-stratifiedkfold) from sklearn when running cross-validation.\n",
    "- Do forget to `set.seed()` before the spilt to make your result reproducible.\n",
    "- **Note:** We are not looking for the best tuned model in the lab so don't spend too much time on grid search. Focus on model evaluation and the business use case of each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable: replace Yes -> 1 and No -> 0\n",
    "new_orders.Returns.replace({'Yes':1, 'No':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set and test set\n",
    "np.random.seed(0)\n",
    "testIdxes = np.random.choice(range(new_orders.shape[0]), size= int(new_orders.shape[0] * .2), replace=False)\n",
    "trainIdxes = list(set(range(new_orders.shape[0]))-set(testIdxes))\n",
    "train_set = new_orders.iloc[trainIdxes]\n",
    "test_set = new_orders.iloc[testIdxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_encoded = pd.get_dummies(train_set[[\"Segment\",'Sub.Category', 'Returns','Times.Returned']])\n",
    "test_set_encoded = pd.get_dummies(test_set[[\"Segment\",'Sub.Category', 'Returns', 'Times.Returned']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_set_encoded.Returns\n",
    "X = train_set_encoded[train_set_encoded.columns[1:]]\n",
    "y_test = test_set_encoded.Returns\n",
    "X_test = test_set_encoded[test_set_encoded.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.711420354844999\n",
      "0.7140768180931956\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logistic = LogisticRegression(C=1e4, solver='lbfgs', multi_class='auto', class_weight=\"balanced\")\n",
    "logistic.fit(X,y)\n",
    "print(logistic.score(X, y))\n",
    "print(logistic.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5793283291089881\n",
      "0.5742834860596607\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cclf = RandomForestClassifier(max_depth=21, random_state=0, class_weight=\"balanced\")\n",
    "cclf.fit(X, y)\n",
    "print(cclf.score(X,y))\n",
    "print(cclf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Evaluating Models\n",
    "- What is the best metric to evaluate your model. Is accuracy good for this case?\n",
    "- Now you have multiple models, which one would you pick? \n",
    "- Can you get any clue from the confusion matrix? What is the meaning of precision and recall in this case? Which one do you care the most? How will your model help the manager make decisions?\n",
    "- **Note:** The last question is open-ended. Your answer could be completely different depending on your understanding of this business problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28093 11189]\n",
      " [  652  1098]]\n",
      "0.711420354844999\n",
      "[[22216 17066]\n",
      " [  195  1555]]\n",
      "0.5793283291089881\n"
     ]
    }
   ],
   "source": [
    "# AIC or BIC (best for descriptive models)\n",
    "# ...\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y, logistic.predict(X)))  # Logistic Regression\n",
    "print( (28093+1098) / (28093+11189+652+1098) )\n",
    "print(confusion_matrix(y, cclf.predict(X)))      # Random Forest\n",
    "print( (22216+1555) / (22216+17066+195+1555) )\n",
    "# initially the score was very high but that is because the training data was not balanced.\n",
    "# Added the option 'balanced' to the LogisticRegression and that brought down the score to a more reasonable number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Problem 7: Feature Engineering Revisit\n",
    "- Is there anything wrong with the new feature we generated? How should we fix it?\n",
    "- ***Hint***: For the real test set, we do not know it will get returned or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
